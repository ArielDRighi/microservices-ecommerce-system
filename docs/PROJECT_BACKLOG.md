# üìã Backlog Completo - Proyecto 3: Ecosistema de Microservicios E-commerce

> **Proyecto:** Sistema de gesti√≥n de inventario y √≥rdenes con arquitectura de microservicios  
> **Stack Principal:** NestJS (Orders) + Go/Gin (Inventory) + API Gateway + Redis + PostgreSQL  
> **Metodolog√≠a:** TDD/BDD con CI/CD incremental  
> **Duraci√≥n Estimada:** 8-10 semanas

---

## üéØ Visi√≥n General del Proyecto

**Objetivo:** Evolucionar el sistema as√≠ncrono de √≥rdenes (Proyecto 2) hacia un ecosistema de microservicios, a√±adiendo un servicio de inventario independiente en Go que maneje la concurrencia de stock con locking optimista y cach√© distribuida.

**Arquitectura Final:**

```
Cliente ‚Üí API Gateway ‚Üí [Orders Service (NestJS)]
                     ‚Üí [Inventory Service (Go/Gin)]
                     ‚Üì
              Message Queue (RabbitMQ)
                     ‚Üì
              Shared PostgreSQL + Redis Cluster
```

---

## üìä M√©tricas de √âxito del Proyecto

- ‚úÖ **Cobertura de Tests:** >70% en ambos servicios
- ‚úÖ **Latencia P95:** <200ms para consultas de inventario
- ‚úÖ **Disponibilidad:** 99.9% (health checks configurados)
- ‚úÖ **Documentaci√≥n:** ADRs completos + API docs (Swagger/OpenAPI)
- ‚úÖ **CI/CD:** Pipeline verde en cada commit
- ‚úÖ **Concurrencia:** Manejo correcto de 100+ requests simult√°neos sin race conditions

---

## üî∑ FASE 0: Technical Spikes

**Objetivo:** Realizar investigaci√≥n t√©cnica y tomar decisiones arquitect√≥nicas cr√≠ticas antes de comenzar el desarrollo.

### Epic 0.1: Technical Spikes y Decisiones Arquitect√≥nicas

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

#### ‚úÖ T0.1.1: Spike - Selecci√≥n de API Gateway para Portfolio

- **Status:** ‚úÖ COMPLETADA (2025-10-16)
- **Decisi√≥n tomada:** **Express custom con http-proxy-middleware**
- **Documento:** [ADR-026: API Gateway Custom con Express](../adr/026-api-gateway-express-custom.md)
- **Contexto:** Necesitamos un gateway que enrute a Orders (NestJS/REST) e Inventory (Go/REST)
- **Opciones evaluadas:**
  - ‚úÖ **Express custom** - SELECCIONADO
    - Control total del c√≥digo y l√≥gica de routing
    - M√°ximo valor educativo (implementar patrones desde cero)
    - Alineaci√≥n con stack actual (Node.js/TypeScript)
    - Bajo overhead (<5ms latencia, <200MB RAM)
  - ‚ùå **Kong** - RECHAZADO
    - Overkill para 2-3 servicios
    - Complejidad operacional (PostgreSQL para metadata)
  - ‚ùå **Traefik** - RECHAZADO
    - Optimizado para Kubernetes (proyecto usa Docker Compose)
    - Features limitadas para autenticaci√≥n JWT custom
- **Stack definido:**
  - Proxy: `http-proxy-middleware`
  - Auth: `jsonwebtoken` (JWT custom)
  - Rate Limiting: `express-rate-limit` + Redis
  - Circuit Breaker: `opossum`
  - Logging: `winston` + `morgan`
  - M√©tricas: `prom-client` (Prometheus)
- **Implementaci√≥n:** Ver Epic 4.1 y 4.2 en Fase 4

#### ‚è≥ T0.1.2: Spike - Testcontainers en Go - Viabilidad para CI/CD

- **Status:** ‚è≥ PENDIENTE
- **Contexto:** Inventory Service (Go) necesita tests de integraci√≥n con PostgreSQL real
- **A investigar:**
  - ¬øTestcontainers funciona bien en GitHub Actions?
  - ¬øTiempo de setup es aceptable? (<2 min ideal)
  - ¬øAlternativas como sqlmock son suficientes para el portfolio?
- **Entregable:** PoC de test con testcontainers + decisi√≥n documentada

#### ‚è≥ T0.1.3: Spike - Estrategia de Comunicaci√≥n S√≠ncrona

- **Status:** ‚è≥ PENDIENTE
- **Contexto:** Orders (NestJS) necesita llamar a Inventory (Go/Gin)
- **Ya decidido:** REST (ambos servicios son RESTful)
- **A definir:**
  - ¬øCliente HTTP nativo de NestJS (@nestjs/axios) o librer√≠a custom?
  - ¬øTimeout strategy? (5s, 10s?)
  - ¬øRetry autom√°tico o manual?
  - ¬øCircuit breaker a nivel de cliente o gateway?
- **Entregable:** ADR con decisiones de implementaci√≥n

#### ‚è≥ T0.1.4: Spike - RabbitMQ vs Redis Pub/Sub para eventos as√≠ncronos

- **Status:** ‚è≥ PENDIENTE
- **Contexto:** Inventory necesita publicar eventos (InventoryReserved, etc.) que Orders consume
- **Opciones:**
  - **RabbitMQ (nuevo en el stack)**
    - ‚úÖ Pro: Garant√≠as de entrega m√°s fuertes
    - ‚úÖ Pro: Queues persistentes
    - ‚ùå Contra: A√±ade complejidad al docker-compose
  - **Redis Pub/Sub (ya ten√©s Redis del Proyecto 2)**
    - ‚úÖ Pro: Infraestructura existente
    - ‚úÖ Pro: M√°s simple
    - ‚ùå Contra: No persiste mensajes (at-most-once delivery)
- **Recomendaci√≥n:** RabbitMQ (demuestra m√°s conocimiento de message brokers)
- **Entregable:** Decisi√≥n documentada + justificaci√≥n t√©cnica

**‚úÖ Definition of Done - Epic 0.1:**

- [ ] Todas las decisiones t√©cnicas cr√≠ticas tomadas y documentadas
- [ ] Al menos 1 PoC ejecutado exitosamente (Testcontainers o API Gateway)
- [ ] Decisiones validadas con criterios de portfolio (claridad, valor demostrativo)
- [ ] ADRs preliminares creados para decisiones arquitect√≥nicas

---

## üî∑ FASE 1: Setup Inicial, Fundamentos y Refactoring

**Objetivo:** Establecer la estructura del monorepo, configurar el servicio de inventario b√°sico en Go, refactorizar Orders Service para arquitectura de microservicios, y tener CI/CD funcional desde el d√≠a 1.

### ‚úÖ Epic 1.1: Estructura del Monorepo **[COMPLETADA]**

**Priority:** CRITICAL | **Effort:** 4h | **Status:** ‚úÖ DONE

#### ‚úÖ T1.1.1: Clonar proyecto 2 a nuevo repositorio

- **Status:** ‚úÖ COMPLETADA
- Nuevo repositorio clonado con historial Git completo
- Remote origin actualizado

#### ‚úÖ T1.1.2: Reestructurar en monorepo multi-servicio

- **Status:** ‚úÖ COMPLETADA
- Estructura de carpetas `services/`, `shared/`, `docs/` creada
- C√≥digo de Orders movido a `services/orders-service/`

#### ‚úÖ T1.1.3: Configurar .gitignore para multi-lenguaje

- **Status:** ‚úÖ COMPLETADA
- `.gitignore` robusto soportando Node.js, Go, Docker, m√∫ltiples IDEs

#### ‚úÖ T1.1.4: Crear README.md principal del ecosistema

- **Status:** ‚è≥ PENDIENTE (pr√≥xima tarea)
- Debe incluir diagrama de arquitectura en Mermaid
- Quick Start unificado
- Estructura del monorepo explicada

#### ‚úÖ T1.1.5: Documentar decisi√≥n en ADR-026-monorepo-structure.md

- **Status:** ‚è≥ PENDIENTE
- Justificar elecci√≥n de monorepo sobre multi-repo
- Pros, contras y alternativas consideradas

**‚úÖ Definition of Done - Epic 1.1:**

- [ ] Estructura de monorepo correctamente organizada
- [ ] .gitignore cubre todos los lenguajes del proyecto
- [ ] README principal con diagrama de arquitectura creado
- [ ] ADR-026 documentando decisi√≥n de monorepo
- [ ] C√≥digo de Orders Service migrado sin p√©rdida de funcionalidad

---

### ‚úÖ Epic 1.2: Inventory Service - Esqueleto B√°sico (Go/Gin) **[COMPLETADA]**

**Priority:** CRITICAL | **Status:** ‚úÖ DONE

#### ‚úÖ T1.2.1: Inicializar proyecto Go con m√≥dulos

- **Status:** ‚úÖ COMPLETADA
- `go.mod` creado con namespace correcto
- Go 1.25 verificado

#### ‚úÖ T1.2.2: Setup estructura hexagonal (Clean Architecture)

- **Status:** ‚úÖ COMPLETADA
- Estructura completa de capas: domain, application, infrastructure, interfaces
- Separaci√≥n clara de responsabilidades

#### ‚úÖ T1.2.3: Instalar dependencias iniciales

- **Status:** ‚úÖ COMPLETADA
- Gin, GORM, Redis, Testify, Logrus instalados
- `go.mod` y `go.sum` actualizados

#### ‚úÖ T1.2.4: Crear main.go b√°sico con Gin

- **Status:** ‚úÖ COMPLETADA
- Servidor HTTP funcional en puerto 8080
- Health check en `/health`
- Graceful shutdown implementado

#### ‚úÖ T1.2.5: Configurar variables de entorno con godotenv

- **Status:** ‚úÖ COMPLETADA
- Sistema de configuraci√≥n robusto con godotenv + envconfig
- `.env.example` creado

#### ‚úÖ T1.2.6: Escribir primer test (health check)

- **Status:** ‚úÖ COMPLETADA
- Test de integraci√≥n del endpoint `/health`
- Makefile con comandos de testing

**‚úÖ Definition of Done - Epic 1.2:**

- [ ] Proyecto Go inicializado con estructura hexagonal
- [ ] Todas las dependencias instaladas y funcionando
- [ ] Servidor HTTP corriendo en puerto 8080
- [ ] Health check funcional con tests pasando
- [ ] Configuraci√≥n de entorno implementada
- [ ] Graceful shutdown funcionando correctamente

---

### Epic 1.3: CI/CD - Pipeline Inicial **[PENDIENTE]**

**Priority:** HIGH | **Dependencies:** T1.2.6

#### ‚è≥ T1.3.1: Crear .github/workflows/inventory-service-ci.yml

- **Status:** ‚è≥ PENDIENTE
- Pipeline con paths filters
- Tests con PostgreSQL y Redis en contenedores
- Coverage m√≠nimo 70%

#### ‚è≥ T1.3.2: Configurar golangci-lint

- **Status:** ‚è≥ PENDIENTE
- Archivo `.golangci.yml` con reglas estrictas
- Integraci√≥n en pipeline CI

#### ‚è≥ T1.3.3: Actualizar CI del Orders Service

- **Status:** ‚è≥ PENDIENTE
- Ajustar paths filters para nueva estructura monorepo
- Verificar que sigue funcionando correctamente

**‚úÖ Definition of Done - Epic 1.3:**

- [ ] Pipeline CI/CD del Inventory Service funcionando
- [ ] Tests corriendo en GitHub Actions con PostgreSQL y Redis
- [ ] Linter golangci-lint integrado y pasando
- [ ] Pipeline del Orders Service actualizado para monorepo
- [ ] Coverage reports generados (target: >70%)
- [ ] Badges de CI/CD a√±adidos al README

---

### Epic 1.4: Docker & Orchestration **[70% COMPLETADA]**

**Priority:** CRITICAL

#### ‚úÖ T1.4.1: Crear docker-compose.yml principal

- **Status:** ‚úÖ COMPLETADA
- Orquestaci√≥n de orders-service e inventory-service
- Infraestructura compartida (PostgreSQL, Redis)
- **Separaci√≥n total del Proyecto 2**: Puertos y nombres √∫nicos

#### ‚úÖ T1.4.2: Configurar bases de datos separadas

- **Status:** ‚úÖ COMPLETADA
- `microservices_orders` para Orders Service
- `microservices_inventory` para Inventory Service
- `microservices_test` para tests
- Script `init-db.sql` funcional

#### ‚úÖ T1.4.3: Dockerfile para Inventory Service

- **Status:** ‚úÖ COMPLETADA
- Multi-stage build
- Imagen optimizada con Alpine

#### ‚è≥ T1.4.4: Dockerfile.dev para desarrollo

- **Status:** ‚è≥ PENDIENTE
- Hot-reload con Air
- Vol√∫menes de c√≥digo montados

#### ‚è≥ T1.4.5: Setup RabbitMQ en docker-compose

- **Status:** ‚è≥ PENDIENTE
- A√±adir servicio RabbitMQ con imagen `rabbitmq:3-management`
- Configurar puerto 5672 (AMQP) y 15672 (Management UI)
- Configurar persistencia de mensajes
- Health check de RabbitMQ
- Documentar acceso a Management UI en INFRASTRUCTURE_REFERENCE.md

**‚úÖ Definition of Done - Epic 1.4:**

- [ ] docker-compose.yml levanta todos los servicios sin errores
- [ ] Bases de datos separadas correctamente configuradas
- [ ] Dockerfiles optimizados (multi-stage builds)
- [ ] RabbitMQ corriendo y accesible
- [ ] Health checks configurados para todos los servicios
- [ ] Documentaci√≥n de puertos actualizada

---

### Epic 1.5: Documentaci√≥n Inicial **[60% COMPLETADA]**

**Priority:** HIGH

#### ‚úÖ T1.5.1: Crear INFRASTRUCTURE_REFERENCE.md

- **Status:** ‚úÖ COMPLETADA
- Documentaci√≥n completa de:
  - Puertos (Proyecto 2 vs Proyecto 3)
  - Bases de datos
  - Credenciales
  - Contenedores Docker
  - Troubleshooting

#### ‚úÖ T1.5.2: Crear QUICK_REFERENCE.md

- **Status:** ‚úÖ COMPLETADA
- Gu√≠a de consulta r√°pida
- Comandos esenciales
- Accesos r√°pidos

#### ‚úÖ T1.5.3: README de cada servicio

- **Status:** ‚úÖ COMPLETADA
- `services/orders-service/README.md`
- `services/inventory-service/README.md`

#### ‚è≥ T1.5.4: README.md principal

- **Status:** ‚è≥ PENDIENTE (pr√≥xima tarea)
- Debe consolidar toda la informaci√≥n
- Diagrama de arquitectura

**‚úÖ Definition of Done - Epic 1.5:**

- [ ] Todos los README creados y actualizados
- [ ] Documentaci√≥n t√©cnica referencia puertos, bases de datos, credenciales
- [ ] Gu√≠a de troubleshooting incluida
- [ ] Quick reference con comandos esenciales documentada

---

### Epic 1.6: Refactoring del Orders Service para Microservicios

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

**Contexto:** El Orders Service del Proyecto 2 fue dise√±ado como monolito con l√≥gica de inventario interna. Debe ser refactorizado para funcionar en un ecosistema de microservicios delegando toda la gesti√≥n de stock al Inventory Service.

#### ‚è≥ T1.6.1: Eliminar l√≥gica de inventario interno del Orders Service

- **Status:** ‚è≥ PENDIENTE
- Remover tabla `inventory` de la base de datos del Orders Service
- Eliminar seeders relacionados con inventario
- Eliminar endpoints internos `/inventory/*` del Orders Service
- Actualizar migraciones para eliminar referencias a inventario
- Crear migraci√≥n de rollback por si es necesario

#### ‚è≥ T1.6.2: Crear InventoryServiceClient (HTTP)

- **Status:** ‚è≥ PENDIENTE
- Crear interface `IInventoryClient` en m√≥dulo com√∫n del Orders Service
- Implementaci√≥n con `@nestjs/axios` para llamadas HTTP
- Manejo de errores de red (timeouts, 5xx, connection refused)
- Retry logic con exponential backoff (3 intentos)
- Logging estructurado de todas las llamadas al servicio externo
- Tests unitarios del cliente con mocks

#### ‚è≥ T1.6.3: Actualizar Saga Pattern para llamadas externas

- **Status:** ‚è≥ PENDIENTE
- Modificar `OrderSaga` para usar `InventoryServiceClient` en lugar de l√≥gica interna
- A√±adir step de compensaci√≥n para fallos de red
- Implementar timeout en llamadas al servicio externo (max 5 segundos)
- Manejar casos de servicio no disponible
- Actualizar tests de saga con cliente HTTP mockeado

#### ‚è≥ T1.6.4: Actualizar variables de entorno del Orders Service

- **Status:** ‚è≥ PENDIENTE
- A√±adir `INVENTORY_SERVICE_URL=http://inventory-service:8080`
- A√±adir `INVENTORY_SERVICE_TIMEOUT=5000`
- A√±adir `INVENTORY_SERVICE_RETRY_ATTEMPTS=3`
- Actualizar `.env.example` con nuevas variables
- Documentar variables en README del Orders Service

#### ‚è≥ T1.6.5: Actualizar tests del Orders Service

- **Status:** ‚è≥ PENDIENTE
- Mockear `InventoryServiceClient` en unit tests
- Crear fixtures para responses del Inventory Service
- Actualizar E2E tests para levantar ambos servicios (docker-compose)
- Tests de timeout y retry logic del cliente HTTP
- Verificar que coverage sigue >70%

**‚úÖ Definition of Done - Epic 1.6:**

- [ ] Orders Service no tiene l√≥gica de inventario interna
- [ ] Todas las operaciones de stock se delegan al Inventory Service v√≠a HTTP
- [ ] Tests pasan con el cliente HTTP mockeado
- [ ] E2E tests funcionan con ambos servicios corriendo en docker-compose
- [ ] Cobertura de tests se mantiene >70%
- [ ] Variables de entorno documentadas

---

## üî∂ FASE 2: Funcionalidad Core del Inventory Service

**Objetivo:** Implementar CRUD completo de inventario con locking optimista para concurrencia, sistema de eventos distribuidos con RabbitMQ, cach√© distribuida con Redis, y gesti√≥n de datos con migraciones.

### Epic 2.1: Domain Layer - Entidades y L√≥gica de Negocio

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T2.1.1: Crear entidad InventoryItem

```go
type InventoryItem struct {
    ID          uuid.UUID
    ProductID   uuid.UUID
    Quantity    int
    Reserved    int
    Available   int          // Calculated: Quantity - Reserved
    Version     int          // For optimistic locking
    CreatedAt   time.Time
    UpdatedAt   time.Time
}
```

#### ‚è≥ T2.1.2: Crear entidad Reservation

```go
type Reservation struct {
    ID              uuid.UUID
    InventoryItemID uuid.UUID
    OrderID         uuid.UUID
    Quantity        int
    Status          ReservationStatus
    ExpiresAt       time.Time
    CreatedAt       time.Time
}
```

#### ‚è≥ T2.1.3: Implementar Value Objects

- `StockQuantity`: Validaciones de cantidad (no negativo)
- `ReservationStatus`: Enum (pending, confirmed, released, expired)

#### ‚è≥ T2.1.4: Definir interfaces de repositorios

```go
type InventoryRepository interface {
    FindByProductID(ctx context.Context, productID uuid.UUID) (*InventoryItem, error)
    Save(ctx context.Context, item *InventoryItem) error
    Update(ctx context.Context, item *InventoryItem) error
    DecrementStock(ctx context.Context, productID uuid.UUID, qty int, version int) error
}
```

#### ‚è≥ T2.1.5: Implementar errores de dominio

- `ErrInsufficientStock`
- `ErrProductNotFound`
- `ErrOptimisticLockFailure`
- `ErrReservationExpired`

**‚úÖ Definition of Done - Epic 2.1:**

- [ ] Todas las entidades de dominio creadas y documentadas
- [ ] Value Objects con validaciones implementadas y testeadas
- [ ] Interfaces de repositorios definidas claramente
- [ ] Errores de dominio implementados con mensajes descriptivos
- [ ] Tests unitarios de entidades con coverage >80%
- [ ] C√≥digo siguiendo principios de Clean Architecture

---

### Epic 2.2: Application Layer - Casos de Uso

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T2.2.1: Caso de uso: Check Availability

- Verificar si hay stock disponible para un producto
- Considerar cantidad reservada

#### ‚è≥ T2.2.2: Caso de uso: Reserve Stock

- Crear reserva temporal (15 min)
- Actualizar cantidad reservada
- **Usar locking optimista** (version field)

#### ‚è≥ T2.2.3: Caso de uso: Confirm Reservation

- Convertir reserva en decremento real de stock
- Liberar cantidad reservada
- **Transaccional**: reserva confirmada = stock decrementado

#### ‚è≥ T2.2.4: Caso de uso: Release Reservation

- Cancelar reserva
- Liberar cantidad reservada de vuelta a disponible

#### ‚è≥ T2.2.5: Caso de uso: Expire Reservations (Cronjob)

- Job que se ejecuta cada minuto
- Libera reservas expiradas (>15 min)

**‚úÖ Definition of Done - Epic 2.2:**

- [ ] Todos los casos de uso implementados siguiendo Clean Architecture
- [ ] Repositorios mockeados en tests de casos de uso
- [ ] Locking optimista correctamente implementado en Reserve Stock
- [ ] Cronjob de expiraci√≥n funcional y testeado
- [ ] Tests unitarios con coverage >80%
- [ ] Manejo de errores apropiado en cada caso de uso

---

### Epic 2.3: Infrastructure Layer - Persistencia

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T2.3.1: Configurar conexi√≥n a PostgreSQL con GORM

- Pool de conexiones
- Logging de queries en desarrollo

#### ‚è≥ T2.3.2: Crear modelos GORM

- `InventoryItemModel`
- `ReservationModel`
- √çndices y constraints

#### ‚è≥ T2.3.3: Implementar InventoryRepositoryImpl

- CRUD completo
- **Locking optimista**: `UPDATE ... WHERE version = ?`

#### ‚è≥ T2.3.4: Crear migraciones SQL

```sql
CREATE TABLE inventory_items (
    id UUID PRIMARY KEY,
    product_id UUID NOT NULL UNIQUE,
    quantity INT NOT NULL CHECK (quantity >= 0),
    reserved INT NOT NULL DEFAULT 0 CHECK (reserved >= 0),
    version INT NOT NULL DEFAULT 1,
    created_at TIMESTAMP NOT NULL,
    updated_at TIMESTAMP NOT NULL
);

CREATE INDEX idx_inventory_product ON inventory_items(product_id);
```

#### ‚è≥ T2.3.5: Configurar Redis para cach√©

- Cachear productos populares
- TTL: 5 minutos
- Invalidaci√≥n al actualizar stock

**‚úÖ Definition of Done - Epic 2.3:**

- [ ] Conexi√≥n a PostgreSQL configurada con pool optimizado
- [ ] Modelos GORM creados con √≠ndices y constraints apropiados
- [ ] InventoryRepositoryImpl implementado con locking optimista
- [ ] Migraciones SQL ejecutables y rollback disponible
- [ ] Redis configurado para cach√©
- [ ] Tests de integraci√≥n con PostgreSQL y Redis (testcontainers)
- [ ] C√≥digo sin race conditions verificado

---

### Epic 2.4: Interfaces Layer - HTTP Handlers

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T2.4.1: Crear handler: GET /api/inventory/:productId

- Retornar stock disponible de un producto
- Leer desde cach√© primero

#### ‚è≥ T2.4.2: Crear handler: POST /api/inventory/reserve

```json
{
  "product_id": "uuid",
  "quantity": 5,
  "order_id": "uuid"
}
```

- Crear reserva temporal

#### ‚è≥ T2.4.3: Crear handler: POST /api/inventory/confirm

- Confirmar reserva y decrementar stock real

#### ‚è≥ T2.4.4: Crear handler: DELETE /api/inventory/reserve/:reservationId

- Cancelar reserva

#### ‚è≥ T2.4.5: Implementar middleware de rate limiting

- Limitar a 100 req/min por IP
- Usar Redis para contadores

**‚úÖ Definition of Done - Epic 2.4:**

- [ ] Todos los endpoints HTTP implementados y documentados
- [ ] Handlers delegando correctamente a casos de uso
- [ ] Validaci√≥n de inputs en todos los endpoints
- [ ] Rate limiting funcional
- [ ] Tests de integraci√≥n de endpoints con httptest
- [ ] Documentaci√≥n de API (comentarios para Swagger)
- [ ] Manejo de errores HTTP apropiado (400, 404, 409, 500)

---

### Epic 2.5: Sistema de Eventos Distribuidos (RabbitMQ)

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

**Contexto:** Implementar comunicaci√≥n as√≠ncrona entre Inventory Service y Orders Service mediante eventos publicados a RabbitMQ.

#### ‚è≥ T2.5.2: Definir eventos de inventario

- **Status:** ‚è≥ PENDIENTE
- Crear schemas de eventos:
  - `InventoryReserved`: cuando se crea una reserva
  - `InventoryConfirmed`: cuando se confirma y decrementa stock
  - `InventoryReleased`: cuando se cancela una reserva
  - `StockDepleted`: cuando un producto llega a quantity = 0
  - `StockReplenished`: cuando se a√±ade stock a un producto
- Documentar estructura de cada evento con ejemplos JSON

#### ‚è≥ T2.5.3: Implementar Publisher en Inventory Service (Go)

- **Status:** ‚è≥ PENDIENTE
- Usar librer√≠a `github.com/rabbitmq/amqp091-go`
- Crear m√≥dulo de eventos con m√©todo `Publish(event Event)`
- Publicar al exchange `inventory.events`
- Garantizar at-least-once delivery
- Manejo de errores de publicaci√≥n
- Logging de todos los eventos publicados

#### ‚è≥ T2.5.4: Implementar Consumer en Orders Service (NestJS)

- **Status:** ‚è≥ PENDIENTE
- Crear m√≥dulo RabbitMQ consumer (adem√°s de Bull existente)
- Suscribirse a eventos de inventario desde queue espec√≠fica
- Procesar eventos y actualizar estado de √≥rdenes
- Idempotencia en procesamiento (evitar duplicados)
- Dead Letter Queue para eventos fallidos

#### ‚è≥ T2.5.5: Crear ADR-027: Estrategia de Comunicaci√≥n

- **Status:** ‚è≥ PENDIENTE
- Documentar decisi√≥n: REST para sync, RabbitMQ para async
- Alternativas consideradas: gRPC, Apache Kafka
- Pros y contras de cada opci√≥n
- Justificaci√≥n de la decisi√≥n tomada

**‚úÖ Definition of Done - Epic 2.5:**

- [ ] RabbitMQ corriendo en docker-compose (desde Fase 1)
- [ ] Todos los eventos de inventario definidos y documentados
- [ ] Inventory Service publica eventos correctamente
- [ ] Orders Service consume y procesa eventos
- [ ] Idempotencia implementada (sin duplicados)
- [ ] ADR-027 documentado
- [ ] Tests de publicaci√≥n y consumo de eventos

---

### Epic 2.6: Sistema de Cach√© Distribuida

**Priority:** HIGH | **Status:** ‚è≥ PENDIENTE

**Contexto:** Optimizar performance del Inventory Service con estrategia de cach√© usando Redis para reducir latencia de consultas.

#### ‚è≥ T2.6.1: Implementar Cache-Aside Pattern en Inventory

- **Status:** ‚è≥ PENDIENTE
- GET `/inventory/:productId` ‚Üí leer de Redis primero
- Si cache miss, leer de PostgreSQL y escribir a Redis
- TTL configurable: 5 minutos por defecto
- Serializaci√≥n eficiente de datos (JSON)
- Manejo de errores de Redis (fallback a PostgreSQL)

#### ‚è≥ T2.6.2: Invalidaci√≥n de cach√© al actualizar stock

- **Status:** ‚è≥ PENDIENTE
- Al reservar stock, invalidar key en Redis
- Al confirmar reserva, invalidar key
- Al liberar reserva, invalidar key
- Usar patr√≥n "write-through" para consistencia
- Logging de operaciones de invalidaci√≥n

#### ‚è≥ T2.6.3: Cach√© de agregaciones

- **Status:** ‚è≥ PENDIENTE
- Cachear query "low stock products" (productos con quantity < 10)
- Cachear "most reserved products" para analytics
- Cachear estad√≠sticas globales de inventario
- TTL m√°s largo para agregaciones (15 min)
- Invalidaci√≥n programada (cronjob)

#### ‚è≥ T2.6.4: Configurar Redis Cluster (opcional para portfolio avanzado)

- **Status:** ‚è≥ PENDIENTE (OPCIONAL)
- Setup master-replica para alta disponibilidad
- Configurar Redis Sentinel para failover autom√°tico
- Documentar arquitectura de Redis distribuido
- Health checks de Redis cluster

**‚úÖ Definition of Done - Epic 2.6:**

- [ ] Cache-Aside pattern funciona correctamente
- [ ] Invalidaci√≥n es inmediata al actualizar datos
- [ ] Latencia de queries con cache <50ms P95
- [ ] Tests de cach√© (hit, miss, invalidaci√≥n)
- [ ] Manejo de errores de Redis sin afectar funcionalidad
- [ ] M√©tricas de cache hit rate implementadas

---

### Epic 2.7: Gesti√≥n de Datos y Migraciones

**Priority:** MEDIUM | **Status:** ‚è≥ PENDIENTE

**Contexto:** Establecer estrategia robusta de migraciones SQL, datos de prueba y sincronizaci√≥n entre servicios.

#### ‚è≥ T2.7.1: Crear migraciones iniciales para Inventory

- **Status:** ‚è≥ PENDIENTE
- `001_create_inventory_items.sql`
- `002_create_reservations.sql`
- `003_add_indexes.sql`
- `004_add_constraints.sql`
- Script de ejecuci√≥n de migraciones en orden
- Verificaci√≥n de integridad despu√©s de cada migraci√≥n

#### ‚è≥ T2.7.2: Crear seeders para desarrollo

- **Status:** ‚è≥ PENDIENTE
- Seed 100 productos en Inventory Service
- Sincronizar UUIDs con productos del Orders Service
- Crear script reutilizable para recrear datos
- Diferentes datasets: dev, test, demo
- Documentar proceso de seeding

#### ‚è≥ T2.7.3: Script de sincronizaci√≥n de datos

- **Status:** ‚è≥ PENDIENTE
- Script que copia `product_ids` de Orders a Inventory
- √ötil al migrar de monolito a microservicios
- Maneja productos nuevos y existentes
- Logging detallado de operaciones
- Validaci√≥n de datos antes de sincronizar

#### ‚è≥ T2.7.4: Estrategia de rollback de migraciones

- **Status:** ‚è≥ PENDIENTE
- Definir proceso manual de rollback
- Crear migraciones "down" para cada migraci√≥n "up"
- Documentar escenarios de rollback
- Tests de migraciones up y down
- Backup autom√°tico antes de migraci√≥n

**‚úÖ Definition of Done - Epic 2.7:**

- [ ] Migraciones se ejecutan sin errores en orden correcto
- [ ] Seeds crean datos consistentes entre servicios
- [ ] Script de sincronizaci√≥n funciona correctamente
- [ ] Rollbacks documentados y testeados
- [ ] Proceso de migraci√≥n documentado en README
- [ ] Backups autom√°ticos configurados

---

## üî∂ FASE 3: Integraci√≥n Orders ‚Üî Inventory

**Objetivo:** Comunicaci√≥n entre servicios v√≠a HTTP y eventos, con compensaci√≥n distribuida y manejo robusto de fallos.

### Epic 3.1: Comunicaci√≥n S√≠ncrona (HTTP)

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T3.1.1: Crear cliente HTTP en Orders Service

- **Status:** ‚è≥ PENDIENTE
- Service: `InventoryServiceClient`
- M√©todos: `checkAvailability()`, `reserveStock()`, `confirmReservation()`
- Configuraci√≥n de timeout y retry desde variables de entorno

#### ‚è≥ T3.1.2: Actualizar Saga de Orders

- **Status:** ‚è≥ PENDIENTE
- **Step 1**: Verificar stock llamando a Inventory Service
- **Step 2**: Reservar stock
- **Step 3**: Procesar pago
- **Step 4**: Confirmar reserva
- **Compensaci√≥n**: Liberar reserva si falla pago
- Logging detallado de cada step

#### ‚è≥ T3.1.3: Implementar Circuit Breaker

- **Status:** ‚è≥ PENDIENTE
- Usar `opossum` o similar en NestJS
- Si Inventory Service est√° ca√≠do, fallar r√°pido
- Configurar thresholds (error rate, timeout)
- Dashboard de estado del circuit breaker

**‚úÖ Definition of Done - Epic 3.1:**

- [ ] InventoryServiceClient implementado y testeado
- [ ] Saga de Orders actualizada con llamadas HTTP
- [ ] Circuit Breaker funcional y configurado
- [ ] Compensaciones funcionan correctamente
- [ ] Tests E2E con ambos servicios corriendo
- [ ] Manejo de timeouts y errores de red
- [ ] Logs estructurados de comunicaci√≥n inter-servicio

---

### Epic 3.2: Comunicaci√≥n As√≠ncrona (Eventos)

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

**Contexto:** Complementar comunicaci√≥n s√≠ncrona con eventos as√≠ncronos para desacoplamiento y notificaciones.

#### ‚è≥ T3.2.1: Publicar eventos desde Inventory

- **Status:** ‚è≥ PENDIENTE
- `StockReserved`: cuando se crea una reserva
- `StockConfirmed`: cuando se confirma y decrementa
- `StockReleased`: cuando se cancela una reserva
- `StockDepleted`: cuando quantity = 0
- Integraci√≥n con Epic 2.5.3 (Publisher ya implementado)

#### ‚è≥ T3.2.2: Consumir eventos en Orders Service

- **Status:** ‚è≥ PENDIENTE
- Actualizar estado de orden al confirmar stock
- Manejar evento StockDepleted (notificar backorders)
- Integraci√≥n con Epic 2.5.4 (Consumer ya implementado)
- Logging de eventos consumidos

**‚úÖ Definition of Done - Epic 3.2:**

- [ ] Todos los eventos de inventario publicados correctamente
- [ ] Orders Service consume y procesa eventos
- [ ] Estado de √≥rdenes se actualiza basado en eventos
- [ ] Tests de integraci√≥n de eventos end-to-end
- [ ] Idempotencia garantizada (sin procesamiento duplicado)
- [ ] Monitoreo de eventos en RabbitMQ Management UI

---

### Epic 3.3: Compensaci√≥n Distribuida y Manejo de Fallos

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

**Contexto:** Implementar estrategias robustas de compensaci√≥n para transacciones distribuidas y manejo de fallos de red entre servicios.

#### ‚è≥ T3.3.1: Implementar patr√≥n Two-Phase Commit simplificado

- **Status:** ‚è≥ PENDIENTE
- **Phase 1 - Reserve**: reserva temporal en Inventory Service
- **Phase 2 - Confirm o Release**: seg√∫n resultado de pago
- Timeout de 15 minutos para confirmaci√≥n autom√°tica
- Auto-release si no se confirma a tiempo (cronjob de Epic 2.2.5)
- Logs detallados de cada fase

#### ‚è≥ T3.3.2: Manejar fallos de red entre servicios

- **Status:** ‚è≥ PENDIENTE
- Si Inventory no responde, retry 3 veces con exponential backoff
- Si falla definitivamente, marcar orden como FAILED
- Registrar error detallado en logs con correlation ID
- Enviar notificaci√≥n al cliente sobre fallo
- Compensaci√≥n: no dejar reservas hu√©rfanas

#### ‚è≥ T3.3.3: Implementar Dead Letter Queue para eventos fallidos

- **Status:** ‚è≥ PENDIENTE
- Si Orders no puede procesar evento de inventario, enviar a DLQ
- Crear endpoint administrativo para revisar DLQ: `GET /admin/dlq`
- Dashboard para monitorear eventos fallidos
- Manual retry de eventos desde DLQ: `POST /admin/dlq/:id/retry`
- Alertas cuando DLQ supera threshold (ej. >10 mensajes)

#### ‚è≥ T3.3.4: Crear tests de "Chaos Engineering" b√°sicos

- **Status:** ‚è≥ PENDIENTE
- **Test 1**: Simular Inventory Service completamente ca√≠do
- **Test 2**: Simular latencia extrema de red (>2 segundos)
- **Test 3**: Simular respuestas malformadas del Inventory Service
- **Test 4**: Simular p√©rdida de conexi√≥n a RabbitMQ
- Verificar que Orders Service no se bloquea ni crashea
- Verificar que compensaciones se ejecutan correctamente

**‚úÖ Definition of Done - Epic 3.3:**

- [ ] Two-Phase Commit funciona correctamente en todos los escenarios
- [ ] Compensaciones previenen √≥rdenes en estado inconsistente
- [ ] DLQ captura eventos fallidos sin p√©rdida
- [ ] Tests de chaos pasan exitosamente
- [ ] No hay reservas hu√©rfanas en la base de datos
- [ ] Sistema resiliente a fallos de red y servicios ca√≠dos
- [ ] Documentaci√≥n de escenarios de fallo y recuperaci√≥n

---

## üî∂ FASE 4: API Gateway

**Objetivo:** Implementar punto de entrada √∫nico con enrutamiento inteligente, funcionalidades avanzadas de nivel empresarial y seguridad robusta.

### Epic 4.1: Setup del API Gateway

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

> **üìå Decisi√≥n Arquitect√≥nica:** Este Epic implementa la decisi√≥n tomada en el Spike T0.1.1 (Fase 0).  
> Ver [ADR-026: API Gateway Custom con Express](../adr/026-api-gateway-express-custom.md) para contexto completo.

#### ‚è≥ T4.1.1: Implementar estructura base del API Gateway

- **Status:** ‚è≥ PENDIENTE
- **Tecnolog√≠a:** Express + http-proxy-middleware (seg√∫n decisi√≥n ADR-026)
- **Tareas:**
  - Crear directorio `services/api-gateway/`
  - Inicializar proyecto Node.js con TypeScript
  - Instalar dependencias: `express`, `http-proxy-middleware`, `helmet`, `compression`, `morgan`, `winston`, `dotenv`
  - Crear `src/index.ts` con servidor Express b√°sico
  - Configurar variables de entorno (`.env.example`)
  - Implementar health check: `GET /health`
  - Configurar puerto (3000) y graceful shutdown
  - Crear Dockerfile para el gateway
  - A√±adir al `docker-compose.yml`
- **Entregable:** API Gateway corriendo en `localhost:3000` con health check funcional

#### ‚è≥ T4.1.2: Configurar rutas

- **Status:** ‚è≥ PENDIENTE

```
/api/orders/*     ‚Üí orders-service:3001
/api/inventory/*  ‚Üí inventory-service:8080
```

- Configuraci√≥n basada en path prefix
- Health check del gateway: `GET /health`

#### ‚è≥ T4.1.3: Implementar autenticaci√≥n centralizada

- **Status:** ‚è≥ PENDIENTE
- Validar JWT en Gateway
- Propagar user info a servicios downstream (header `X-User-ID`)
- Endpoints p√∫blicos vs protegidos
- Manejo de tokens expirados

**‚úÖ Definition of Done - Epic 4.1:**

- [ ] API Gateway funcional con tecnolog√≠a seleccionada
- [ ] Rutas configuradas y enrutando correctamente
- [ ] Autenticaci√≥n JWT centralizada funcionando
- [ ] Health check del gateway implementado
- [ ] Tests de enrutamiento pasando
- [ ] Documentaci√≥n de configuraci√≥n

---

### Epic 4.2: Funcionalidades Avanzadas del API Gateway

**Priority:** HIGH | **Status:** ‚è≥ PENDIENTE

**Contexto:** Implementar features de nivel empresarial en el API Gateway para demostrar conocimiento avanzado de arquitectura de microservicios.

#### ‚è≥ T4.2.1: Implementar Rate Limiting global

- **Status:** ‚è≥ PENDIENTE
- Limitar a 100 requests/minuto por IP
- Usar Redis para contadores distribuidos
- Retornar 429 Too Many Requests cuando se excede
- Headers informativos: `X-RateLimit-Limit`, `X-RateLimit-Remaining`, `X-RateLimit-Reset`
- Configuraci√≥n diferente para usuarios autenticados vs an√≥nimos

#### ‚è≥ T4.2.2: Implementar Request/Response Logging

- **Status:** ‚è≥ PENDIENTE
- Log de todos los requests entrantes con correlation ID
- Log de response times para m√©tricas
- Log de errores 4xx y 5xx con detalles
- Integraci√≥n con Winston para logging estructurado
- Redacci√≥n de datos sensibles (passwords, tokens)

#### ‚è≥ T4.2.3: Implementar Circuit Breaker a nivel Gateway

- **Status:** ‚è≥ PENDIENTE
- Monitorear error rate de cada servicio downstream
- Si un servicio tiene >50% error rate, abrir circuit
- Retornar 503 Service Unavailable inmediatamente
- Auto-cierre despu√©s de timeout configurable (30 segundos)
- Dashboard de estado de circuit breakers

#### ‚è≥ T4.2.4: Configurar CORS policies

- **Status:** ‚è≥ PENDIENTE
- Permitir or√≠genes espec√≠ficos (whitelist configurable)
- Configurar m√©todos HTTP permitidos (GET, POST, PUT, DELETE, PATCH)
- Configurar headers permitidos y expuestos
- Preflight requests (OPTIONS) manejados correctamente
- Variables de entorno para configuraci√≥n

#### ‚è≥ T4.2.5: Implementar Load Balancing b√°sico (OPCIONAL)

- **Status:** ‚è≥ PENDIENTE (OPCIONAL)
- Detectar m√∫ltiples instancias del mismo servicio
- Algoritmo round-robin simple para distribuci√≥n
- Health checks para remover instancias no saludables
- Sticky sessions si es necesario

#### ‚è≥ T4.2.6: Documentar patrones implementados en el Gateway

- **Status:** ‚è≥ PENDIENTE
- **Nota:** La decisi√≥n de tecnolog√≠a ya est√° en ADR-026
- **Objetivo:** Documentar C√ìMO se implementaron los patrones avanzados
- **Contenido:**
  - Arquitectura de middleware stack (orden y raz√≥n)
  - Configuraci√≥n de Circuit Breaker (thresholds, timeouts)
  - Estrategia de Rate Limiting (por IP, por usuario, por endpoint)
  - Logging strategy (qu√© se loggea, qu√© se redacta)
  - M√©tricas expuestas (latencia, error rate, throughput)
  - Troubleshooting guide para operadores
- **Entregable:** Documento en `docs/api-gateway/ARCHITECTURE.md` o ADR-027 si aplica

**‚úÖ Definition of Done - Epic 4.2:**

- [ ] Rate limiting funcional y configurado
- [ ] Request/Response logging estructurado implementado
- [ ] Circuit breaker previene cascading failures
- [ ] CORS configurado correctamente
- [ ] ADR-028 documentado con decisi√≥n clara
- [ ] Tests de cada funcionalidad avanzada
- [ ] M√©tricas del gateway expuestas (Prometheus)

---

### Epic 4.3: Seguridad del Ecosistema

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

**Contexto:** Implementar medidas de seguridad robustas para proteger el ecosistema de microservicios.

#### ‚è≥ T4.3.1: Implementar Service-to-Service Authentication

- **Status:** ‚è≥ PENDIENTE
- API keys compartidas entre servicios internos
- O JWT espec√≠fico para comunicaci√≥n inter-servicio
- Inventory Service valida requests de Orders Service
- Prevenir acceso directo desde internet (solo via Gateway)
- Rotation policy de API keys documentada

#### ‚è≥ T4.3.2: Implementar Input Validation en Inventory Service

- **Status:** ‚è≥ PENDIENTE
- Validar formato de UUIDs en todos los endpoints
- Validar rangos de quantity (min: 1, max: 1000)
- Sanitizar todos los inputs para prevenir SQL injection
- Retornar 400 Bad Request con errores descriptivos
- Usar librer√≠a de validaci√≥n (validator en Go)

#### ‚è≥ T4.3.3: Rate Limiting por servicio

- **Status:** ‚è≥ PENDIENTE
- Inventory Service: 200 req/min por cliente
- Orders Service: 100 req/min por usuario
- Rate limiting diferenciado por endpoint (GET vs POST)
- Configuraci√≥n por variables de entorno

#### ‚è≥ T4.3.4: Secrets Management

- **Status:** ‚è≥ PENDIENTE
- Usar Docker secrets o variables de entorno protegidas
- NO commitear credenciales en c√≥digo fuente
- Documentar proceso de rotaci√≥n de passwords de BD
- Usar secretos diferentes en dev, test y prod
- `.env` en `.gitignore`, `.env.example` como template

**‚úÖ Definition of Done - Epic 4.3:**

- [ ] Servicios no son accesibles sin autenticaci√≥n apropiada
- [ ] Input validation previene ataques comunes (SQL injection, XSS)
- [ ] Secrets management implementado correctamente
- [ ] Rate limiting por servicio funcional
- [ ] Documentaci√≥n de seguridad completa
- [ ] Audit de seguridad b√°sico realizado
- [ ] No hay credenciales en el c√≥digo fuente

---

## üî∂ FASE 5: Testing Completo

**Objetivo:** Implementar suite completa de tests (unitarios, integraci√≥n, E2E, concurrencia) con √©nfasis en tests de concurrencia y performance.

### Epic 5.1: Tests de Inventory Service

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T5.1.1: Tests unitarios de Domain

- **Status:** ‚è≥ PENDIENTE
- Entidades, Value Objects, errores de dominio
- Coverage target: >80%

#### ‚è≥ T5.1.2: Tests de Application Layer

- **Status:** ‚è≥ PENDIENTE
- Casos de uso mockeando repositorios
- Verificar l√≥gica de negocio

#### ‚è≥ T5.1.3: Tests de integraci√≥n

- **Status:** ‚è≥ PENDIENTE
- Con PostgreSQL y Redis reales (Testcontainers)
- Verificar interacci√≥n con infraestructura

#### ‚è≥ T5.1.4: Tests E2E del API

- **Status:** ‚è≥ PENDIENTE
- Flujo completo de reserva ‚Üí confirmaci√≥n ‚Üí liberaci√≥n
- Tests con servidor HTTP real

**‚úÖ Definition of Done - Epic 5.1:**

- [ ] Tests unitarios con coverage >80%
- [ ] Tests de application layer con mocks correctos
- [ ] Tests de integraci√≥n con testcontainers funcionando
- [ ] Tests E2E cubriendo flujos principales
- [ ] Pipeline CI ejecuta todos los tests
- [ ] Reportes de coverage generados

---

### Epic 5.2: Tests de Integraci√≥n entre Servicios

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T5.2.1: Test: Crear orden con verificaci√≥n de stock

- **Status:** ‚è≥ PENDIENTE
- Orders Service llama a Inventory Service
- Flujo happy path completo

#### ‚è≥ T5.2.2: Test: Orden falla si no hay stock

- **Status:** ‚è≥ PENDIENTE
- Verificar compensaci√≥n (reserva liberada)
- Verificar estado de orden: FAILED

#### ‚è≥ T5.2.3: Test de concurrencia b√°sico

- **Status:** ‚è≥ PENDIENTE
- 100 requests simult√°neos comprando el √∫ltimo √≠tem
- Solo 1 debe tener √©xito
- Verificar en BD: stock final correcto

**‚úÖ Definition of Done - Epic 5.2:**

- [ ] Tests de integraci√≥n entre servicios pasando
- [ ] Compensaciones verificadas funcionando
- [ ] Test de concurrencia b√°sico exitoso
- [ ] Ambos servicios levantados en docker-compose para tests
- [ ] Tests documentados y repetibles

---

### Epic 5.3: Suite Completa de Tests de Concurrencia

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

**Contexto:** El feature estrella del proyecto - demostrar manejo correcto de concurrencia con locking optimista y prevenci√≥n de race conditions.

#### ‚è≥ T5.3.1: Test: Race condition al reservar √∫ltimo √≠tem

- **Status:** ‚è≥ PENDIENTE
- 100 goroutines intentan reservar simult√°neamente quantity=1
- Solo 1 debe tener √©xito (200 OK)
- 99 deben recibir 409 Conflict (insufficient stock)
- Verificar en base de datos: `reserved = 1`, no m√°s
- Usar testcontainers para PostgreSQL real
- Medir tiempo de ejecuci√≥n del test

#### ‚è≥ T5.3.2: Test: Locking optimista con versiones

- **Status:** ‚è≥ PENDIENTE
- Thread 1 lee item (version=1)
- Thread 2 lee item (version=1)
- Thread 1 actualiza con √©xito (version=2)
- Thread 2 intenta actualizar con version=1 ‚Üí FAIL 409
- Verificar mensaje de error apropiado: "Optimistic lock failure"
- Documentar comportamiento esperado

#### ‚è≥ T5.3.3: Test: Reservas expiradas liberan stock correctamente

- **Status:** ‚è≥ PENDIENTE
- Crear 10 reservas con expiraci√≥n en 1 segundo
- Esperar 2 segundos
- Ejecutar cronjob de expiraci√≥n manualmente
- Verificar que stock disponible aument√≥ exactamente en 10 unidades
- Verificar estado de reservas: expired

#### ‚è≥ T5.3.4: Test de carga con K6

- **Status:** ‚è≥ PENDIENTE
- Crear script de K6 para simular 1000 usuarios concurrentes
- Cada usuario intenta crear una orden simult√°neamente
- Medir latencia P95 (target: <200ms)
- Verificar 0 race conditions en stock
- Generar reporte HTML con resultados
- Documentar configuraci√≥n de K6

#### ‚è≥ T5.3.5: Test: Deadlock prevention

- **Status:** ‚è≥ PENDIENTE
- Orden 1 intenta reservar producto A y B
- Orden 2 intenta reservar producto B y A (orden inverso)
- Ambas √≥rdenes se ejecutan simult√°neamente
- Verificar que no hay deadlock (timeout o success en ambas)
- Medir tiempo de resoluci√≥n
- Implementar estrategia de prevenci√≥n si es necesario

**‚úÖ Definition of Done - Epic 5.3:**

- [ ] 100% de tests de concurrencia pasan consistentemente
- [ ] 0 race conditions detectadas en m√∫ltiples ejecuciones
- [ ] Locking optimista funciona correctamente
- [ ] Reporte de K6 demuestra performance bajo carga
- [ ] Tests de deadlock pasan (no hay bloqueos)
- [ ] Documentaci√≥n completa de tests de concurrencia
- [ ] Video/GIF demostrando tests de concurrencia (portfolio)

---

### Epic 5.4: Optimizaci√≥n y Performance

**Priority:** MEDIUM | **Status:** ‚è≥ PENDIENTE

**Contexto:** Optimizar performance del sistema y demostrar conocimiento de benchmarking y tuning.

#### ‚è≥ T5.4.1: Benchmarking de endpoints cr√≠ticos

- **Status:** ‚è≥ PENDIENTE
- Benchmark: GET `/inventory/:id` (target: <50ms P95)
- Benchmark: POST `/inventory/reserve` (target: <100ms P95)
- Usar herramienta como Apache Bench o wrk
- Generar reportes de performance
- Comparar con y sin cach√©

#### ‚è≥ T5.4.2: Optimizaci√≥n de queries SQL

- **Status:** ‚è≥ PENDIENTE
- A√±adir √≠ndices compuestos donde sea necesario
- Analizar EXPLAIN de queries lentas
- Optimizar JOINs innecesarios
- Documentar decisiones de indexaci√≥n
- Medir impacto antes/despu√©s

#### ‚è≥ T5.4.3: Connection Pooling optimizado

- **Status:** ‚è≥ PENDIENTE
- PostgreSQL: max 20 conexiones por servicio
- Redis: max 10 conexiones
- Timeout de conexi√≥n: 5 segundos
- Monitoring de pool saturation
- Configuraci√≥n documentada

#### ‚è≥ T5.4.4: Compresi√≥n de responses

- **Status:** ‚è≥ PENDIENTE
- Implementar gzip para responses >1KB
- Medir impacto en latencia
- Balance entre CPU y bandwidth
- Configurar en API Gateway
- Comparar tama√±os de payload

**‚úÖ Definition of Done - Epic 5.4:**

- [ ] Benchmarks documentados con resultados
- [ ] Optimizaciones implementadas mejoran performance medible
- [ ] Connection pools configurados √≥ptimamente
- [ ] Compresi√≥n reduce payload size >50%
- [ ] Documentaci√≥n de optimizaciones realizadas
- [ ] Gr√°ficas before/after de performance

---

## üî∂ FASE 6: Observabilidad y Monitoreo

**Objetivo:** Implementar logging estructurado, m√©tricas, health checks avanzados y distributed tracing para observabilidad completa del ecosistema.

### Epic 6.1: Logging Estructurado

**Priority:** HIGH | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T6.1.1: Implementar Winston en Orders (ya hecho)

- **Status:** ‚úÖ COMPLETADA (desde Proyecto 2)

#### ‚è≥ T6.1.2: Implementar Logrus/Zap en Inventory

- **Status:** ‚è≥ PENDIENTE
- Logging estructurado con JSON output

#### ‚è≥ T6.1.3: Correlation IDs entre servicios

- **Status:** ‚è≥ PENDIENTE
- Propagar correlation ID entre servicios
- Incluir en todos los logs

**‚úÖ Definition of Done - Epic 6.1:**

- [ ] Logging estructurado en ambos servicios
- [ ] Correlation IDs funcionando end-to-end
- [ ] Logs en formato JSON
- [ ] Diferentes niveles de log configurables

---

### Epic 6.2: M√©tricas

**Priority:** HIGH | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T6.2.1: Exponer m√©tricas Prometheus

- **Status:** ‚è≥ PENDIENTE
- `/metrics` en ambos servicios
- M√©tricas custom: `inventory_stock_level`, `orders_processed_total`

#### ‚è≥ T6.2.2: Configurar Grafana Dashboard

- **Status:** ‚è≥ PENDIENTE
- Dashboard unificado con m√©tricas de ambos servicios

**‚úÖ Definition of Done - Epic 6.2:**

- [ ] M√©tricas Prometheus expuestas en ambos servicios
- [ ] Grafana dashboard funcional
- [ ] M√©tricas custom implementadas
- [ ] Alertas b√°sicas configuradas

---

### Epic 6.3: Health Checks Avanzados

**Priority:** MEDIUM | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T6.3.1: Health check con dependencias

- **Status:** ‚è≥ PENDIENTE
- Verificar conexi√≥n a PostgreSQL
- Verificar conexi√≥n a Redis
- Verificar conexi√≥n a RabbitMQ
- Retornar `503` si alguna falla

**‚úÖ Definition of Done - Epic 6.3:**

- [ ] Health checks verifican todas las dependencias
- [ ] Respuestas correctas (200 healthy, 503 unhealthy)
- [ ] Detalle de qu√© dependencia fall√≥

---

### Epic 6.4: Distributed Tracing

**Priority:** CRITICAL | **Status:** ‚è≥ PENDIENTE

**Contexto:** Implementar tracing distribuido para debugging y an√°lisis de performance end-to-end en el ecosistema de microservicios.

#### ‚è≥ T6.4.1: Implementar OpenTelemetry en ambos servicios

- **Status:** ‚è≥ PENDIENTE
- Instalar SDK de OpenTelemetry para Go (Inventory)
- Instalar SDK de OpenTelemetry para Node.js (Orders)
- Instrumentar endpoints HTTP autom√°ticamente
- Instrumentar llamadas a base de datos
- Propagar trace context en headers HTTP

#### ‚è≥ T6.4.2: Setup Jaeger para visualizaci√≥n de traces

- **Status:** ‚è≥ PENDIENTE
- A√±adir Jaeger all-in-one a docker-compose
- Configurar exporters en ambos servicios hacia Jaeger
- UI disponible en `http://localhost:16686`
- Configurar sampling (100% en dev, 10% en prod)

#### ‚è≥ T6.4.3: Crear Correlation IDs unificados

- **Status:** ‚è≥ PENDIENTE
- Generar UUID √∫nico en API Gateway para cada request
- Propagar en header `X-Correlation-ID`
- Incluir correlation ID en todos los logs estructurados
- Incluir en respuestas de error para debugging

#### ‚è≥ T6.4.4: Dashboards de latencia cross-service

- **Status:** ‚è≥ PENDIENTE
- Crear Grafana dashboard con m√©tricas de tracing
- Visualizar latencia P50/P95/P99 por servicio
- Visualizar tiempo total de procesamiento de una orden
- Visualizar tasa de errores distribuida por servicio

**‚úÖ Definition of Done - Epic 6.4:**

- [ ] OpenTelemetry implementado en ambos servicios
- [ ] Traces visibles en Jaeger UI
- [ ] Correlation IDs presentes en todos los logs
- [ ] Dashboard de Grafana con m√©tricas de latencia
- [ ] Latencias medibles end-to-end
- [ ] Documentaci√≥n de uso de tracing

---

## üî∂ FASE 7: Documentaci√≥n Final y Deploy

**Objetivo:** Completar documentaci√≥n t√©cnica y de arquitectura, y preparar el proyecto para deployment.

### Epic 7.1: Documentaci√≥n

**Priority:** HIGH | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T7.1.1: Completar todos los ADRs

- **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T7.1.2: Documentaci√≥n de API (Swagger/OpenAPI)

- **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T7.1.3: Gu√≠a de deployment

- **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T7.1.4: Runbooks para operaci√≥n

- **Status:** ‚è≥ PENDIENTE

**‚úÖ Definition of Done - Epic 7.1:**

- [ ] Todos los ADRs completados
- [ ] API documentada con Swagger
- [ ] Gu√≠a de deployment escrita
- [ ] Runbooks para escenarios comunes

---

### Epic 7.2: Deploy

**Priority:** MEDIUM | **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T7.2.1: Configurar Docker Compose para producci√≥n

- **Status:** ‚è≥ PENDIENTE

#### ‚è≥ T7.2.2: (Opcional) Deploy a Kubernetes

- **Status:** ‚è≥ PENDIENTE (OPCIONAL)

#### ‚è≥ T7.2.3: (Opcional) Deploy a Railway/Render

- **Status:** ‚è≥ PENDIENTE (OPCIONAL)

**‚úÖ Definition of Done - Epic 7.2:**

- [ ] Docker Compose production-ready
- [ ] Variables de entorno separadas por ambiente
- [ ] Proceso de deployment documentado

---

### Epic 7.3: Documentaci√≥n de Arquitectura

**Priority:** MEDIUM | **Status:** ‚è≥ PENDIENTE

**Contexto:** Crear documentaci√≥n visual y t√©cnica de la arquitectura del sistema usando C4 Model y diagramas de secuencia.

#### ‚è≥ T7.3.1: Diagrama C4 Model - Nivel 1 (Context)

- **Status:** ‚è≥ PENDIENTE
- Identificar actores externos (Cliente, Admin)
- Mostrar sistema completo como caja negra
- Incluir sistemas externos (Email Service, Payment Gateway)
- Documentar interacciones de alto nivel

#### ‚è≥ T7.3.2: Diagrama C4 Model - Nivel 2 (Containers)

- **Status:** ‚è≥ PENDIENTE
- Descomponer en: API Gateway, Orders Service, Inventory Service
- Incluir: Bases de datos, Redis, RabbitMQ
- Mostrar protocolos de comunicaci√≥n (HTTP, AMQP)
- Documentar puertos y endpoints

#### ‚è≥ T7.3.3: Diagrama de Secuencia: Happy Path de Orden

- **Status:** ‚è≥ PENDIENTE
- Flujo completo: Cliente ‚Üí Gateway ‚Üí Orders ‚Üí Inventory ‚Üí Payment
- Incluir tiempos aproximados de cada paso
- Mostrar comunicaci√≥n s√≠ncrona y as√≠ncrona
- Documentar estados de la orden en cada paso

#### ‚è≥ T7.3.4: Diagrama de Secuencia: Compensaci√≥n en Fallo

- **Status:** ‚è≥ PENDIENTE
- Flujo cuando falla el procesamiento de pago
- Orders llama a Inventory para liberar reserva
- Actualizaci√≥n de estado de orden
- Notificaci√≥n al cliente

#### ‚è≥ T7.3.5: Documento: Estrategia de Deployment

- **Status:** ‚è≥ PENDIENTE
- Orden correcto de inicio de servicios
- Healthchecks y readiness probes configurados
- Estrategia de rollback en caso de fallo
- Checklist de deployment

**‚úÖ Definition of Done - Epic 7.3:**

- [ ] Todos los diagramas creados en Mermaid
- [ ] Documentaci√≥n incluida en repositorio
- [ ] Diagramas referenciados en README principal
- [ ] Estrategia de deployment documentada
- [ ] Diagramas exportados como im√°genes (PNG/SVG)

#### ‚è≥ T7.2.3: (Opcional) Deploy a Railway/Render

---

## üìä Estado Actual del Proyecto

### ‚úÖ Completado

- [x] Estructura de monorepo (Epic 1.1 - parcial)
- [x] Inventory Service - Esqueleto b√°sico (Epic 1.2 - completo)
- [x] Docker Compose con separaci√≥n total (Epic 1.4 - parcial)
- [x] Documentaci√≥n de infraestructura (Epic 1.5 - parcial)
- [x] Makefile ra√≠z

### üîÑ En Progreso - Fase 1

- [ ] **Epic 1.1**: Completar README principal y ADR-026
- [ ] **Epic 1.3**: CI/CD pipelines para ambos servicios
- [ ] **Epic 1.4**: A√±adir RabbitMQ y Dockerfile.dev
- [ ] **Epic 1.5**: Completar documentaci√≥n inicial
- [ ] **Epic 1.6**: Refactoring del Orders Service (NUEVO - CR√çTICO)

### ‚è≥ Pr√≥ximos Pasos Inmediatos

1. **Fase 0**: Ejecutar Technical Spikes (decisiones arquitect√≥nicas cr√≠ticas)
2. **Completar Fase 1**: Todas las √©picas 1.1 - 1.6
3. **Tag v3.0.0-phase-1**: Marcar finalizaci√≥n de setup inicial
4. **Empezar Fase 2**: Domain Layer del Inventory Service

### üö® Cambios Importantes en este Backlog

**Actualizaci√≥n basada en an√°lisis exhaustivo de gaps (ver GAPS_backlog.md):**

- ‚úÖ **A√±adida Fase 0**: Technical Spikes para decisiones arquitect√≥nicas cr√≠ticas (4 spikes)
- ‚úÖ **Fase 1 ampliada**: Epic 1.6 (Refactoring Orders Service) + T1.4.5 (RabbitMQ setup)
- ‚úÖ **Fase 2 ampliada**: Epic 2.5 (Eventos RabbitMQ), Epic 2.6 (Cach√© Distribuida), Epic 2.7 (Migraciones)
- ‚úÖ **Fase 3 ampliada**: Epic 3.3 (Compensaci√≥n Distribuida y Manejo de Fallos)
- ‚úÖ **Fase 4 ampliada**: Epic 4.2 (Features Avanzados Gateway), Epic 4.3 (Seguridad)
- ‚úÖ **Fase 5 ampliada**: Epic 5.3 (Tests de Concurrencia), Epic 5.4 (Optimizaci√≥n y Performance)
- ‚úÖ **Fase 6 ampliada**: Epic 6.4 (Distributed Tracing con OpenTelemetry y Jaeger)
- ‚úÖ **Fase 7 ampliada**: Epic 7.3 (Documentaci√≥n de Arquitectura con C4 Model)
- ‚úÖ **Definition of Done a√±adido**: A TODOS los √©picos del proyecto (0.1 - 7.3)

**Resumen de gaps integrados:**

- üî¥ **11 Gaps identificados** en an√°lisis (5 cr√≠ticos, 6 medios/altos)
- üî¥ **50+ tareas nuevas** a√±adidas al backlog original
- üî¥ **Cobertura completa**: Desde setup hasta deployment production-ready

**Total del proyecto actualizado:**

- **8 Fases** (0-7): Desde Technical Spikes hasta Deployment
- **~35 √âpicas**: Cubriendo todos los aspectos de microservicios
- **~150+ Tareas**: Detalladas y con criterios claros
- **Definition of Done**: En cada epic para garantizar calidad

---

## üìù Notas Importantes

### Separaci√≥n Proyecto 2 vs Proyecto 3

| Componente         | Proyecto 2                         | Proyecto 3                                          |
| ------------------ | ---------------------------------- | --------------------------------------------------- |
| **Repo**           | `ecommerce-async-resilient-system` | `microservices-ecommerce-system`                    |
| **Orders Port**    | 3000                               | **3001**                                            |
| **Inventory Port** | N/A                                | **8080**                                            |
| **PostgreSQL**     | 5432                               | **5433**                                            |
| **Redis**          | 6379                               | **6380**                                            |
| **RabbitMQ**       | N/A                                | **5672** (AMQP), **15672** (UI)                     |
| **Bases de Datos** | `ecommerce_async`                  | `microservices_orders`<br>`microservices_inventory` |
| **Contenedores**   | `ecommerce-*`                      | `microservices-*`                                   |

### Documentaci√≥n de Referencia

- [INFRASTRUCTURE_REFERENCE.md](docs/INFRASTRUCTURE_REFERENCE.md) - Puertos, BDs, credenciales
- [QUICK_REFERENCE.md](QUICK_REFERENCE.md) - Gu√≠a r√°pida de comandos
- [GAPS_backlog.md](docs/GAPS_backlog.md) - An√°lisis detallado de gaps identificados

---

**√öltima actualizaci√≥n:** 2025-10-16  
**Autor:** Ariel D. Righi  
**Proyecto:** Microservices E-commerce System (Proyecto 3)
